{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KWXD03Qnsb1l"
   },
   "source": [
    "# Trabalho de Tópicos Especiais II (unisinos 2019/02)\n",
    "## Uso de processamento de linguagem natural para identificação de análises positivas e negativas, através de reviews em hoteis da europa.\n",
    "\n",
    "### Trabalho realizado por:\n",
    "- Francielle\n",
    "- Gabriel Castro\n",
    "- Matheus Hans\n",
    "- Savana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KWXD03Qnsb1l"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gabriel.fernandes\\AppData\\Roaming\\nltk_data..\n",
      "[nltk_data]     .\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\gabriel.fernandes\\AppData\\Roaming\\nltk_data..\n",
      "[nltk_data]     .\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\gabriel.fernandes\\AppData\\Roaming\\nltk_data..\n",
      "[nltk_data]     .\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\gabriel.fernandes\\AppData\\Roaming\\nltk_data..\n",
      "[nltk_data]     .\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\gabriel.fernandes\\AppData\\Roaming\\nltk_data..\n",
      "[nltk_data]     .\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy # linear algebra\n",
    "import pandas # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import nltk # natural language toolkit\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as pyplot # use to plot graphs like MATLAB\n",
    "\n",
    "from scipy import linalg # using to processing matrix objects\n",
    "from nltk.corpus import treebank\n",
    "from tkinter import *\n",
    "from IPython.display import Image\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('treebank')\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "#import os\n",
    "#for dirname, _, filenames in os.walk('/Repositórios/GitHub/Personal/Unisinos-TopicosEspeciaisII-PLN-LeituraTextual'):\n",
    "#    for filename in filenames:\n",
    "#        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset.\n",
    "data = pandas.read_csv(r'src/review_hotel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am so angry that i made this post available...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My room was dirty and I was afraid to walk ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You When I booked with your company on line y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Backyard of the hotel is total mess shouldn t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review\n",
       "0   I am so angry that i made this post available...\n",
       "1   Rooms are nice but for elderly a bit difficul...\n",
       "2   My room was dirty and I was afraid to walk ba...\n",
       "3   You When I booked with your company on line y...\n",
       "4   Backyard of the hotel is total mess shouldn t..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring the top 5 observations.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>Bed was really comfortable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Beautiful hotel with views of the park Transp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>No Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Large clean rooms with a nice size comfy bed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>Well equipped nice room Traditinal but modern...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review\n",
       "338                        Bed was really comfortable \n",
       "339   Beautiful hotel with views of the park Transp...\n",
       "340                                        No Positive\n",
       "341   Large clean rooms with a nice size comfy bed ...\n",
       "342   Well equipped nice room Traditinal but modern..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring the last 5 observations.\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describing the datasets.\n",
    "# data.describe()\n",
    "\n",
    "# null or missing values in the dataset.\n",
    "# data.isnull().sum()\n",
    "\n",
    "# checking the assumption -> 0 reviews will have missing values in last_review and reviews_per_month columns.\n",
    "# assumption_test = data.loc[(data.last_review.isnull()) & (data.reviews_per_month.isnull()), ['number_of_reviews',  'last_reviews', 'reviews_per_month']]\n",
    "# assumption_test.head()\n",
    "\n",
    "# check the shape of the created dataframe and the number of null values\n",
    "# assumption_test.shape\n",
    "\n",
    "# filling the missing values in reviews_per_month with 0.\n",
    "# data.reviews_per_month.fillna(0, inplace=True)\n",
    "\n",
    "# Checking if the changes made are reflected.\n",
    "# data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple of an information extraction architecture \n",
    "\n",
    "<img src=\"src/img/ie-architecture-extraction-information.png\" height=\"600\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rooms',\n",
       " 'are',\n",
       " 'nice',\n",
       " 'but',\n",
       " 'for',\n",
       " 'elderly',\n",
       " 'a',\n",
       " 'bit',\n",
       " 'difficult',\n",
       " 'as',\n",
       " 'most',\n",
       " 'rooms',\n",
       " 'are',\n",
       " 'two',\n",
       " 'story',\n",
       " 'with',\n",
       " 'narrow',\n",
       " 'steps',\n",
       " 'So',\n",
       " 'ask',\n",
       " 'for',\n",
       " 'single',\n",
       " 'level',\n",
       " 'Inside',\n",
       " 'the',\n",
       " 'rooms',\n",
       " 'are',\n",
       " 'very',\n",
       " 'very',\n",
       " 'basic',\n",
       " 'just',\n",
       " 'tea',\n",
       " 'coffee',\n",
       " 'and',\n",
       " 'boiler',\n",
       " 'and',\n",
       " 'no',\n",
       " 'bar',\n",
       " 'empty',\n",
       " 'fridge']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get one row from data frame and convert to string \n",
    "# after, get each word on the phrase\n",
    "\n",
    "# it's possible use nltk.tokenize.sent_tokenize(text) to split phrases, i.e. A beautifull day. I'll workout. ==> ['A beautifull day.', 'I'll workout.]\n",
    "# the only problem here is that the function return the dot together, so, maybe after this use a replace function would be necessary\n",
    "\n",
    "sentence = data.iloc[1]['Review']\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link to understand what means each part-of-speech tag and chunk tags\n",
    "\n",
    "- <a href=\"https://www.clips.uantwerpen.be/pages/mbsp-tags\">Penn Treebank II tag set</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Rooms', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('nice', 'JJ'),\n",
       " ('but', 'CC'),\n",
       " ('for', 'IN'),\n",
       " ('elderly', 'RB'),\n",
       " ('a', 'DT'),\n",
       " ('bit', 'NN'),\n",
       " ('difficult', 'JJ'),\n",
       " ('as', 'IN'),\n",
       " ('most', 'JJS'),\n",
       " ('rooms', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('two', 'CD'),\n",
       " ('story', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('narrow', 'JJ'),\n",
       " ('steps', 'NNS'),\n",
       " ('So', 'RB'),\n",
       " ('ask', 'VB'),\n",
       " ('for', 'IN'),\n",
       " ('single', 'JJ'),\n",
       " ('level', 'NN'),\n",
       " ('Inside', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('rooms', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('very', 'RB'),\n",
       " ('very', 'RB'),\n",
       " ('basic', 'JJ'),\n",
       " ('just', 'RB'),\n",
       " ('tea', 'JJ'),\n",
       " ('coffee', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('boiler', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('no', 'DT'),\n",
       " ('bar', 'NN'),\n",
       " ('empty', 'RB'),\n",
       " ('fridge', 'NN')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged = nltk.pos_tag(tokens)\n",
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify named entities, if it's a person or something different, like a organization\n",
    "entities = nltk.chunk.ne_chunk(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  Rooms/NNS\n",
      "  are/VBP\n",
      "  nice/JJ\n",
      "  but/CC\n",
      "  for/IN\n",
      "  elderly/RB\n",
      "  a/DT\n",
      "  bit/NN\n",
      "  difficult/JJ\n",
      "  as/IN\n",
      "  most/JJS\n",
      "  rooms/NNS\n",
      "  are/VBP\n",
      "  two/CD\n",
      "  story/NN\n",
      "  with/IN\n",
      "  narrow/JJ\n",
      "  steps/NNS\n",
      "  So/RB\n",
      "  ask/VB\n",
      "  for/IN\n",
      "  single/JJ\n",
      "  level/NN\n",
      "  Inside/IN\n",
      "  the/DT\n",
      "  rooms/NNS\n",
      "  are/VBP\n",
      "  very/RB\n",
      "  very/RB\n",
      "  basic/JJ\n",
      "  just/RB\n",
      "  tea/JJ\n",
      "  coffee/NN\n",
      "  and/CC\n",
      "  boiler/NN\n",
      "  and/CC\n",
      "  no/DT\n",
      "  bar/NN\n",
      "  empty/RB\n",
      "  fridge/NN)\n"
     ]
    }
   ],
   "source": [
    "print(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-0991521d5919>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtreebank\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparsed_sents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mentities\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\nltk\\collections.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    170\u001b[0m             \u001b[1;31m# Handle negative indices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m                 \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'index out of range'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "#t = treebank.parsed_sents()[entities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    PP -> P NP\n",
    "    NP -> Det N | Det N PP | 'I'\n",
    "    VP -> V NP | VP PP\n",
    "    Det -> 'in' | 'my'\n",
    "    N -> 'game' | 'sport'\n",
    "    V -> 'doing'\n",
    "    P -> 'in'\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = nltk.ChartParser(grammar)\n",
    "for tree in parser.parser(tokens):\n",
    "    print(tree)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Untitled1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
